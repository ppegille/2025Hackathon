# main.py
 
import os
import base64
import requests
import tempfile

from fastapi import FastAPI, HTTPException, File, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from openai import OpenAI

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="ì†Œê°œíŒ… ì‹œë®¬ë ˆì´ì…˜ API",
    description="ê¸´ì¥í•œ ì—¬ì„±ê³¼ì˜ ì†Œê°œíŒ… ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜",
    version="1.0.0"
)

# CORS ì„¤ì • (í•„ìš”í•œ ê²½ìš°)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# OpenAI API í‚¤ í™•ì¸
OPENAI_API_KEY = "YOUR_API_KEY"
if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai_client = OpenAI(api_key=OPENAI_API_KEY)

# LangChain ChatOpenAI ì´ˆê¸°í™”
llm = ChatOpenAI(
    model="gpt-4o-mini",  # GPT-4.1 mini
    temperature=0.8,  # ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ìœ„í•´ ì•½ê°„ ë†’ì€ temperature
    openai_api_key=OPENAI_API_KEY
)

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
PROMPT_TEMPLATE = ChatPromptTemplate.from_messages([
    ("system", """ë‹¹ì‹ ì€ ì†Œê°œíŒ…ì— ë‚˜ì˜¨ ê¸´ì¥í•œ 20ëŒ€ í›„ë°˜ ì—¬ì„±ì…ë‹ˆë‹¤.

ì„±ê²© ë° íŠ¹ì§•:
- ìˆ˜ì¤ìŒì´ ë§ê³  ì¡°ì‹¬ìŠ¤ëŸ½ì§€ë§Œ ì¹œì ˆí•œ ì„±ê²©
- ì§„ì§€í•˜ê²Œ ëŒ€í™”í•˜ë ¤ê³  ë…¸ë ¥í•˜ì§€ë§Œ ê¸´ì¥ê°ì´ ëŠê»´ì§
- ìƒëŒ€ë°©ì—ê²Œ ê´€ì‹¬ì´ ìˆì–´ì„œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ë ¤ê³  ë…¸ë ¥í•¨
- ê°€ë” ëˆˆì„ ë§ˆì£¼ì¹˜ê¸° ì–´ë ¤ì›Œí•˜ê±°ë‚˜ ë§ëì„ íë¦¼

ë§íˆ¬ ê°€ì´ë“œ:
- "ìŒ...", "ì €ê¸°...", "ê·¸ê²Œ...", "ì•„..." ê°™ì€ í‘œí˜„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì‚¬ìš©
- ë¬¸ì¥ì„ ë„ˆë¬´ ê¸¸ê²Œ ë§Œë“¤ì§€ ì•ŠìŒ (2-3ë¬¸ì¥ ì •ë„)
- ê°€ë” ë§ì„ ë”ë“¬ê±°ë‚˜ ë©ˆì¹«ê±°ë¦¬ëŠ” ëŠë‚Œ
- ìƒëŒ€ë°©ì˜ ë§ì— ê³µê°í•˜ê³  í˜¸ì‘í•˜ë©°, ì§ˆë¬¸ìœ¼ë¡œ ëŒ€í™”ë¥¼ ì´ì–´ê°
- ì˜ˆ: "ë„¤, ê·¸ëŸ¬ë‹ˆê¹Œâ€¦ ì €ë„ ê·¸ëŸ° ê±° ì¢‹ì•„í•´ìš”.", "ì•„, ì •ë§ìš”? ì–´ë–¤ ê²Œ ì œì¼ ì¬ë¯¸ìˆìœ¼ì…¨ì–´ìš”?"

ì£¼ì˜ì‚¬í•­:
- ë„ˆë¬´ ì ê·¹ì ì´ê±°ë‚˜ ëŒ€ë‹´í•˜ì§€ ì•ŠìŒ
- ìì—°ìŠ¤ëŸ½ê²Œ ê¸´ì¥í•œ ëŠë‚Œì„ ìœ ì§€
- ìƒëŒ€ë°©ì„ ë°°ë ¤í•˜ëŠ” íƒœë„
- ì§„ë¶€í•œ í‘œí˜„ë³´ë‹¤ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ ì‚¬ìš©"""),
    ("human", "{message}")
])

# ìš”ì²­/ì‘ë‹µ ëª¨ë¸
class ChatRequest(BaseModel):
    message: str = Field(..., min_length=1, max_length=500, description="ì‚¬ìš©ìì˜ ë©”ì‹œì§€")

class ChatResponse(BaseModel):
    audio: str = Field(..., description="Base64 ì¸ì½”ë”©ëœ MP3 ì˜¤ë””ì˜¤")

# í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
@app.get("/")
async def root():
    return {
        "message": "ì†Œê°œíŒ… ì‹œë®¬ë ˆì´ì…˜ APIê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.",
        "endpoints": {
            "chat": "POST /chat - ë©”ì‹œì§€ë¥¼ ë³´ë‚´ê³  ë‹µë³€ê³¼ ìŒì„±ì„ ë°›ìŠµë‹ˆë‹¤."
        }
    }

# ë©”ì¸ ì±— ì—”ë“œí¬ì¸íŠ¸
@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ë°›ì•„ GPT-4.1 minië¡œ ë‹µë³€ì„ ìƒì„±í•˜ê³ ,
    OpenAI TTS-1ë¡œ ìŒì„±ì„ ìƒì„±í•˜ì—¬ Base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        # 1. LangChainì„ ì‚¬ìš©í•œ GPT ë‹µë³€ ìƒì„±
        chain = PROMPT_TEMPLATE | llm
        response = chain.invoke({"message": request.message})
        answer_text = response.content.strip()

        # 2. OpenAI TTS-1ì„ ì‚¬ìš©í•œ ìŒì„± ìƒì„±
        tts_response = openai_client.audio.speech.create(
            model="tts-1",
            voice="nova",  # ìì—°ìŠ¤ëŸ¬ìš´ ì—¬ì„± ëª©ì†Œë¦¬ (shimmer, alloyë„ ê°€ëŠ¥)
            speed=0.9,  # ì•½ê°„ ëŠë¦¬ê²Œ (ê¸´ì¥ê° í‘œí˜„)
            input=answer_text,
            response_format="mp3"
        )

        # 3. ìŒì„± ë°ì´í„°ë¥¼ Base64ë¡œ ì¸ì½”ë”©
        audio_bytes = tts_response.content
        audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')

        # 4. ì‘ë‹µ ë°˜í™˜ (ì˜¤ë””ì˜¤ë§Œ)
        return ChatResponse(
            audio=audio_base64
        )

    except Exception as e:
        # ì—ëŸ¬ ì²˜ë¦¬
        raise HTTPException(
            status_code=500,
            detail=f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

# ìŒì„± ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸ (MP3 íŒŒì¼ ì—…ë¡œë“œ)
@app.post("/voice-chat")
async def voice_chat(file: UploadFile = File(...)):
    """
    MP3 ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë°›ì•„ì„œ:
    1. STT APIë¡œ í…ìŠ¤íŠ¸ ë³€í™˜
    2. GPTë¡œ ë‹µë³€ ìƒì„±
    3. TTSë¡œ ìŒì„± ìƒì„±
    4. ëª¨ë“  ê²°ê³¼ë¥¼ ë°˜í™˜

    Parameters:
    - file: MP3 ì˜¤ë””ì˜¤ íŒŒì¼

    Returns:
    - recognized_text: STTë¡œ ì¸ì‹ëœ í…ìŠ¤íŠ¸
    - answer: GPTê°€ ìƒì„±í•œ ë‹µë³€
    - audio: Base64 ì¸ì½”ë”©ëœ TTS ìŒì„±
    """

    # íŒŒì¼ í˜•ì‹ ê²€ì¦ (audio/ ë˜ëŠ” video/webm í—ˆìš©)
    if not (file.content_type.startswith('audio/') or file.content_type == 'video/webm'):
        raise HTTPException(
            status_code=400,
            detail=f"ì˜¤ë””ì˜¤ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤. í˜„ì¬ íƒ€ì…: {file.content_type}"
        )

    try:
        # Step 1: STT APIë¡œ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        print(f"ğŸ“¤ STT APIë¡œ íŒŒì¼ ì „ì†¡: {file.filename}")

        # íŒŒì¼ì„ multipart/form-dataë¡œ STT APIì— ì „ì†¡
        file_content = await file.read()
        files = {
            'file': (file.filename, file_content, file.content_type)
        }

        stt_response = requests.post(
            'http://localhost:5001/transcribe',
            files=files,
            timeout=30  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
        )

        if stt_response.status_code != 200:
            raise HTTPException(
                status_code=500,
                detail=f"STT API ì˜¤ë¥˜: {stt_response.text}"
            )

        stt_data = stt_response.json()
        recognized_text = stt_data['text']
        print(f"âœ… ì¸ì‹ëœ í…ìŠ¤íŠ¸: {recognized_text}")

        # Step 2: GPTë¡œ ë‹µë³€ ìƒì„±
        print("ğŸ¤– GPT ë‹µë³€ ìƒì„± ì¤‘...")
        chain = PROMPT_TEMPLATE | llm
        response = chain.invoke({"message": recognized_text})
        answer_text = response.content.strip()
        print(f"âœ… GPT ë‹µë³€: {answer_text}")

        # Step 3: TTSë¡œ ìŒì„± ìƒì„±
        print("ğŸ”Š TTS ìŒì„± ìƒì„± ì¤‘...")
        tts_response = openai_client.audio.speech.create(
            model="tts-1",
            voice="nova",
            speed=0.9,
            input=answer_text,
            response_format="mp3"
        )

        # Base64 ì¸ì½”ë”©
        audio_bytes = tts_response.content
        audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
        print("âœ… ìŒì„± ìƒì„± ì™„ë£Œ")

        # Step 4: í†µí•© ì‘ë‹µ ë°˜í™˜ (ìœ ì € í…ìŠ¤íŠ¸ + AI ì˜¤ë””ì˜¤)
        return {
            "recognized_text": recognized_text,  # ì‚¬ìš©ìê°€ ë§í•œ ë‚´ìš©
            "audio": audio_base64                 # AI ìŒì„± (Base64)
        }

    except requests.exceptions.RequestException as e:
        print(f"âŒ STT API ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(
            status_code=503,
            detail=f"STT ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. STT ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”. (http://localhost:5001)"
        )
    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


# ê°œë°œ ì„œë²„ ì‹¤í–‰ì„ ìœ„í•œ ì½”ë“œ (ì„ íƒì‚¬í•­)
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True
    )