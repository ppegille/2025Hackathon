import { useEffect, useRef, useState } from 'react'
import { vars } from '@/vars.css'

interface VolumeInputProps {
  /** ë…¹ìŒ ì™„ë£Œ ì‹œ ì½œë°± */
  onSubmit?: (audioBlob: Blob) => void
  /** ë³¼ë¥¨ ë³€í™” ì½œë°± */
  onVolumeChange?: (level: number) => void
  setVolumeLevel: (level: number) => void
  isDone: boolean
  setIsDone: (prev:boolean) => void
}

const silenceThreshold = 50
const speechStartThreshold = 50
const silenceDuration = 2000

export function VolumeInput({
  onSubmit,
  onVolumeChange,
  setVolumeLevel,
  isDone,
  setIsDone
}: VolumeInputProps) {
  const [message, setMessage] = useState('ì‹œì‘ ëŒ€ê¸°ì¤‘...')

  const audioContextRef = useRef<AudioContext | null>(null)
  const analyserRef = useRef<AnalyserNode | null>(null)
  const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const audioChunksRef = useRef<Blob[]>([])
  const silenceTimerRef = useRef<number | null>(null)
  const animationFrameRef = useRef<number | null>(null)
  const isRecordingRef = useRef(false)
  const hasSpeechStartedRef = useRef(false)

  // ì˜¤ë””ì˜¤ ë³¼ë¥¨ ë¶„ì„
  const analyzeVolume = () => {
    if (!analyserRef.current || !isRecordingRef.current) {
      return
    }

    const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount)
    analyserRef.current.getByteFrequencyData(dataArray)

    // RMS (Root Mean Square) ê³„ì‚°
    const sum = dataArray.reduce((acc, val) => acc + val * val, 0)
    const rms = Math.sqrt(sum / dataArray.length)
    const level = Math.min(100, (rms / 128) * 100) // 0-100ìœ¼ë¡œ ì •ê·œí™”

    setVolumeLevel(level)
    onVolumeChange?.(level)

    // ë””ë²„ê¹…: ë³¼ë¥¨ ë ˆë²¨ì„ ì£¼ê¸°ì ìœ¼ë¡œ ì¶œë ¥ (ë§¤ 50í”„ë ˆì„ë§ˆë‹¤)
    if (Math.random() < 0.02) {
      console.log(`ë³¼ë¥¨ ë ˆë²¨: ${level.toFixed(1)}, ìŒì„± ì‹œì‘ë¨: ${hasSpeechStartedRef.current}, ì¹¨ë¬µ íƒ€ì´ë¨¸: ${silenceTimerRef.current ? 'ON' : 'OFF'}`)
    }

    if (!hasSpeechStartedRef.current) {
      if (level >= speechStartThreshold) {
        hasSpeechStartedRef.current = true
        setMessage('ë…¹ìŒ ì¤‘... (ì¹¨ë¬µí•˜ë©´ ìë™ ì¢…ë£Œ)')
        console.log('âœ… ìŒì„± ê°ì§€! ì¹¨ë¬µ ê°ì§€ ì‹œì‘')
      }
    } else {
      if (level < silenceThreshold) {
        // ì¹¨ë¬µ ì‹œì‘
        if (!silenceTimerRef.current) {
          console.log(`â±ï¸ ì¹¨ë¬µ ì‹œì‘ (ë ˆë²¨: ${level.toFixed(1)}) - ${silenceDuration}ms íƒ€ì´ë¨¸ ì‹œì‘`)
          silenceTimerRef.current = window.setTimeout(() => {
            console.log('ğŸ›‘ ì¹¨ë¬µìœ¼ë¡œ ì¸í•œ ë…¹ìŒ ì¢…ë£Œ')
            stopRecording()
          }, silenceDuration)
        }
      } else {
        // ì†Œë¦¬ ê°ì§€ - ì¹¨ë¬µ íƒ€ì´ë¨¸ ë¦¬ì…‹
        if (silenceTimerRef.current) {
          console.log(`ğŸ”Š ì†Œë¦¬ ê°ì§€ (ë ˆë²¨: ${level.toFixed(1)}) - ì¹¨ë¬µ íƒ€ì´ë¨¸ ë¦¬ì…‹`)
          clearTimeout(silenceTimerRef.current)
          silenceTimerRef.current = null
        }
      }
    }

    animationFrameRef.current = requestAnimationFrame(analyzeVolume)
  }

  // ë…¹ìŒ ì‹œì‘
  const startRecording = async () => {
    try {
      setIsDone(false)
      setMessage('ë§ˆì´í¬ ì ‘ê·¼ ì¤‘...')

      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        },
      })

      // ì´ì „ AudioContextê°€ ìˆë‹¤ë©´ ì™„ì „íˆ ì¢…ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        console.log('â³ ì´ì „ AudioContext ì¢…ë£Œ ëŒ€ê¸° ì¤‘...')
        await audioContextRef.current.close()
        audioContextRef.current = null
      }

      // AudioContext ì„¤ì • (ì™„ì „íˆ ìƒˆë¡œ ìƒì„±)
      console.log('ğŸ§ ìƒˆë¡œìš´ AudioContext ìƒì„±')
      audioContextRef.current = new AudioContext()
      sourceRef.current =
        audioContextRef.current.createMediaStreamSource(stream)
      analyserRef.current = audioContextRef.current.createAnalyser()
      analyserRef.current.fftSize = 256
      analyserRef.current.smoothingTimeConstant = 0.8
      sourceRef.current.connect(analyserRef.current)

      // ì´ì „ MediaRecorder ëª…ì‹œì ìœ¼ë¡œ ì •ë¦¬
      if (mediaRecorderRef.current) {
        console.log('ğŸ§¹ ì´ì „ MediaRecorder ì •ë¦¬')
        mediaRecorderRef.current.ondataavailable = null
        mediaRecorderRef.current.onstop = null
        mediaRecorderRef.current = null
      }

      // MediaRecorder ì„¤ì • - Opus ì½”ë± ëª…ì‹œ
      const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus')
        ? 'audio/webm;codecs=opus'
        : MediaRecorder.isTypeSupported('audio/webm')
        ? 'audio/webm'
        : 'audio/mp4'

      console.log(`ğŸ¤ MediaRecorder ìƒì„±: ${mimeType}`)
      mediaRecorderRef.current = new MediaRecorder(stream, {
        mimeType,
        audioBitsPerSecond: 128000, // ëª…ì‹œì ìœ¼ë¡œ ë¹„íŠ¸ë ˆì´íŠ¸ ì„¤ì •
      })

      audioChunksRef.current = []

      mediaRecorderRef.current.ondataavailable = (event) => {
        if (event.data.size > 0) {
          console.log(`ë°ì´í„° ì²­í¬ ìˆ˜ì‹ : ${event.data.size} bytes`)
          audioChunksRef.current.push(event.data)
        }
      }

      mediaRecorderRef.current.onstop = () => {
        console.log('ğŸ“¦ onstop ì´ë²¤íŠ¸ ë°œìƒ - Blob ìƒì„± ì‹œì‘')
        // ëª¨ë“  ë°ì´í„°ê°€ ìˆ˜ì§‘ë  ë•Œê¹Œì§€ ì¶©ë¶„íˆ ëŒ€ê¸°
        setTimeout(() => {
          console.log(`ì´ ì²­í¬ ê°œìˆ˜: ${audioChunksRef.current.length}`)
          const audioBlob = new Blob(audioChunksRef.current, { type: mimeType })
          console.log(`ë…¹ìŒ ì™„ë£Œ: ${audioBlob.size} bytes, type: ${mimeType}`)

          // ìµœì†Œ í¬ê¸° ê²€ì¦ (5KB ì´ìƒ - WebM í—¤ë”ë¥¼ í¬í•¨í•œ ìµœì†Œ í¬ê¸°)
          if (audioBlob.size > 5000) {
            onSubmit?.(audioBlob)
            setMessage('ë¶„ì„ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”')
          } else {
            console.warn(`ë…¹ìŒ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤: ${audioBlob.size} bytes`)
            setMessage('ìŒì„±ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ - ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”')
            // ìë™ ì¬ì‹œì‘ (ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹œê°„ ì¶©ë¶„íˆ í™•ë³´)
            setTimeout(() => startRecording(), 2000)
          }

          // Blob ìƒì„± í›„ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì •ë¦¬
          if (mediaRecorderRef.current) {
            mediaRecorderRef.current.ondataavailable = null
            mediaRecorderRef.current.onstop = null
            console.log('ğŸ“¤ Blob ì „ì†¡ ì™„ë£Œ - ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì œê±°')
          }
        }, 300)
      }

      // timesliceë¥¼ ë” í¬ê²Œ ì„¤ì •í•˜ì—¬ ì•ˆì •ì„± í–¥ìƒ
      mediaRecorderRef.current.start(500) // 500msë§ˆë‹¤ ë°ì´í„° ìˆ˜ì§‘

      isRecordingRef.current = true
      hasSpeechStartedRef.current = false
      setMessage('ë§ì”€í•´ì£¼ì„¸ìš”... (ìŒì„±ì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘)')

      analyzeVolume()
    } catch (error) {
      console.error('ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨:', error)
      setMessage('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤')
    }
  }

  // ë…¹ìŒ ì¤‘ì§€
  const stopRecording = () => {
    setMessage('ì²˜ë¦¬ ì¤‘...')

    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current)
      animationFrameRef.current = null
    }

    isRecordingRef.current = false
    hasSpeechStartedRef.current = false

    // íƒ€ì´ë¨¸ ì •ë¦¬
    if (silenceTimerRef.current) {
      clearTimeout(silenceTimerRef.current)
      silenceTimerRef.current = null
    }

    // MediaRecorder ì¤‘ì§€
    if (
      mediaRecorderRef.current &&
      mediaRecorderRef.current.state !== 'inactive'
    ) {
      // ë²„í¼ì— ë‚¨ì€ ë°ì´í„°ë¥¼ ëª¨ë‘ ìˆ˜ì§‘
      if (mediaRecorderRef.current.state === 'recording') {
        mediaRecorderRef.current.requestData()
      }

      mediaRecorderRef.current.stop()
      console.log('ğŸ›‘ MediaRecorder.stop() í˜¸ì¶œ - onstop ì´ë²¤íŠ¸ ëŒ€ê¸° ì¤‘')

      // ìŠ¤íŠ¸ë¦¼ íŠ¸ë™ ì •ë¦¬
      mediaRecorderRef.current.stream
        .getTracks()
        .forEach((track) => {
          track.stop()
          console.log(`íŠ¸ë™ ì •ë¦¬: ${track.kind}`)
        })
    }

    // ì£¼ì˜: ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ëŠ” onstop ì½œë°±ì—ì„œ ì œê±°ë¨!
    // MediaRecorder ì¸ìŠ¤í„´ìŠ¤ëŠ” ëª…ì‹œì ìœ¼ë¡œ null ì²˜ë¦¬í•˜ì—¬ ë‹¤ìŒ ë…¹ìŒ ì‹œ ì™„ì „íˆ ìƒˆë¡œ ìƒì„±ë˜ë„ë¡ ë³´ì¥
    // (startRecordingì—ì„œ ì¶”ê°€ ì •ë¦¬ ìˆ˜í–‰)

    if (sourceRef.current) {
      sourceRef.current.disconnect()
      sourceRef.current = null
    }

    // AudioContext ì¢…ë£Œ (ë¹„ë™ê¸°ë¡œ ì¢…ë£Œë§Œ ì‹œì‘, startRecordingì—ì„œ ì™„ì „ ì¢…ë£Œ ëŒ€ê¸°)
    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
      audioContextRef.current.close().catch((err) => {
        console.warn('AudioContext ì¢…ë£Œ ì¤‘ ê²½ê³ :', err)
      })
      // ì£¼ì˜: ì—¬ê¸°ì„œëŠ” null ì²˜ë¦¬ ì•ˆí•¨ (startRecordingì—ì„œ ì™„ì „ ì¢…ë£Œ í™•ì¸ í›„ null ì²˜ë¦¬)
    }

    // ë¶„ì„ê¸° ì •ë¦¬
    analyserRef.current = null

    setVolumeLevel(0)
    console.log('ğŸ§¹ ë…¹ìŒ ë¦¬ì†ŒìŠ¤ ì™„ì „ ì •ë¦¬ ì™„ë£Œ')
  }

  // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ ìë™ ì‹œì‘
  useEffect(() => {
    startRecording()

    return () => {
      stopRecording()
    }
  }, [])

  // isDoneì´ trueê°€ ë˜ë©´ ìë™ìœ¼ë¡œ ë…¹ìŒ ì¬ì‹œì‘
  useEffect(() => {
    console.log(isDone)
    if (isDone) {
      console.log('ğŸ’¬ ëŒ€ë‹µ ì™„ë£Œ - ë…¹ìŒ ì¬ì‹œì‘ ì¤€ë¹„')
      // ì´ì „ ë…¹ìŒ ì„¸ì…˜ ì™„ì „íˆ ì •ë¦¬
      stopRecording()
      // ì¶©ë¶„í•œ ëŒ€ê¸° ì‹œê°„ í›„ ì¬ì‹œì‘ (ë¸Œë¼ìš°ì €ê°€ ë¦¬ì†ŒìŠ¤ ì™„ì „íˆ í•´ì œí•  ì‹œê°„ í™•ë³´)
      const restartTimer = setTimeout(() => {
        console.log('ğŸ¤ ë…¹ìŒ ì¬ì‹œì‘ ì‹¤í–‰')
        startRecording()
      }, 2000)

      return () => clearTimeout(restartTimer)
    }
  }, [isDone])

  return (
    <div
      style={{
        position: 'absolute',
        left: '20px',
        top: '10px',
        zIndex: 10,
        display: 'flex',
        flexDirection: 'column',
        gap: vars.spacing.md,
        padding: vars.spacing.md,
        backgroundColor: vars.colors.mainXLight,
        borderRadius: vars.radius.lg,
        border: `2px solid ${vars.colors.mainBorder}`,
      }}
    >
      <div
        style={{
          fontSize: '20px',
          fontWeight: vars.font.weight.medium,
          color: vars.colors.label,
        }}
      >
        {message}
      </div>
      {isRecordingRef.current && (
        <button
          onClick={() => {
            console.log('ìˆ˜ë™ ë…¹ìŒ ì¢…ë£Œ ë²„íŠ¼ í´ë¦­')
            stopRecording()
          }}
          style={{
            padding: '10px 20px',
            backgroundColor: vars.colors.main,
            color: 'white',
            border: 'none',
            borderRadius: vars.radius.md,
            cursor: 'pointer',
            fontSize: '16px',
            fontWeight: vars.font.weight.medium,
          }}
        >
          ë…¹ìŒ ì¢…ë£Œ
        </button>
      )}
    </div>
  )
}
